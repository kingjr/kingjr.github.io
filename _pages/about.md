---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

I am a CNRS researcher at the Ecole Normale Sup√©rieure detached to Meta AI, where I lead the Brain & AI group.
We work on identifying the brain and computational bases of human intelligence, with a focus on language.
We develop deep learning techniques to decode and model intracranial recordings, magneto-encephalography and functional magnetic resonance imaging.

News
====

[Toward a realistic model of speech processing in the brain with self-supervised learning](https://arxiv.org/abs/2206.01685)
---------
Millet\*, Caucheteux\*, Orhan, Boubenec, Gramfort, Dunbar, Pallier & King, <i>arXiv</i> 2022

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">üî•Preprint out: <br><br>`Toward a realistic model of speech processing in the brain with self-supervised learning‚Äô:<a href="https://t.co/rJH6t6H6sm">https://t.co/rJH6t6H6sm</a><br><br>by J. Millet*, <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>* and our wonderful team:<br><br>The 3 main results summarized below üëá <a href="https://t.co/mdrJpbrb3M">pic.twitter.com/mdrJpbrb3M</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1533720262344073218?ref_src=twsrc%5Etfw">June 6, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



[Brains and algorithms partially converge in natural language processing](https://www.nature.com/articles/s42003-022-03036-1)
---------
Caucheteux, King, <i>Nature Communications Biology</i> 2022

<blockquote class="twitter-tweet" data-dnt="true"><p lang="en" dir="ltr">üéâPaper out: ‚ÄòBrains and algorithms partially converge in natural language processing‚Äô<br> <br>by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, and now freely available at Nature <a href="https://twitter.com/CommsBio?ref_src=twsrc%5Etfw">@CommsBio</a>:<a href="https://t.co/MpenOUaKwS">https://t.co/MpenOUaKwS</a><br> <br>The summary thread below üëá <a href="https://t.co/gMruZgGIOv">pic.twitter.com/gMruZgGIOv</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1496425017474695169?ref_src=twsrc%5Etfw">February 23, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


[Long-range and hierarchical language predictions in brains and algorithms](https://arxiv.org/abs/2111.14232)
---------
Caucheteux, Gramfort & King, <i>arXiv</i> 2021

<b>tl;dr:</b>We track language predictions in the brain and show that, unlike modern algorithms, they are hierarchical and apply to a variety of temporal scopes.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">‚ÄòLong-range and hierarchical language predictions in brains and algorithms‚Äô<br> <br>Check-out our latest paper <a href="https://t.co/rwfVCVLRWA">https://t.co/rwfVCVLRWA</a> by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a> <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a><br> <br>tl;dr: Unlike deep language models, the brain makes long-range &amp; hierarchical predictions<br> <br>Thread belowüëá <a href="https://t.co/iP0BEYBjip">pic.twitter.com/iP0BEYBjip</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1465716332264103940?ref_src=twsrc%5Etfw">November 30, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

[Model-based analysis of brain activity reveals the hierarchy of language](https://hal.inria.fr/hal-03361430)
---------
Caucheteux, Gramfort & King, <i>EMNLP</i> 2021

<b>tl;dr:</b>We show how deep language algorithms help reveal the hierarchical organization of language integration in the brain.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Model-based analysis of brain activity reveals the hierarchy of language&quot;<br><br>Our EMNLP paper by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a> <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; myself is out: <a href="https://t.co/BxvrbZNkPt">https://t.co/BxvrbZNkPt</a><br><br>It shows (w/ emoji-based equations!) how deepnets can efficiently recover the language hierarchy in the<br><br>Summaryüëá<br>1/7 <a href="https://t.co/3QOcTfsivu">pic.twitter.com/3QOcTfsivu</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1447909791435825159?ref_src=twsrc%5Etfw">October 12, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


[GPT-2‚Äôs activations predict the degree of semantic comprehension in the human brain](https://www.biorxiv.org/content/10.1101/2021.04.20.440622v3)
---------
Caucheteux, Gramfort & King, <i>bioRxiv</i> 2021

<b>tl;dr:</b>The more we understand text, the more our brain responds like GPT-2.


<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our latest paper is out: <br><br>GPT-2‚Äôs activations predict the degree of semantic comprehension in the human brain, by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a><a href="https://t.co/Xjc8IaXT64">https://t.co/Xjc8IaXT64</a><br> <br>The summary thread below üëá <br>1/8 <a href="https://t.co/GF39doySMu">pic.twitter.com/GF39doySMu</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1402611813032857612?ref_src=twsrc%5Etfw">June 9, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


[Disentangling Syntax and Semantics in the Brain with Deep Networks](http://proceedings.mlr.press/v139/caucheteux21a.html)
---------
Caucheteux, Gramfort & King, <i>ICML</i> 2021

<b>tl;dr:</b>The similarity between deep nets and the brain allow us to decompose syntax and semantics in the brain.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Disentangling Syntax and Semantics in the Brain with Deep Networks&quot;<br><br>Go check out our latest <a href="https://twitter.com/icmlconf?ref_src=twsrc%5Etfw">@icmlconf</a> paper : <a href="https://t.co/4YPK7vJRsJ">https://t.co/4YPK7vJRsJ</a><br>by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a>, <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a> &amp; <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a><br><br>The summary thread below üëá <a href="https://t.co/v0kxjtBtVP">pic.twitter.com/v0kxjtBtVP</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1418216893182185473?ref_src=twsrc%5Etfw">July 22, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


[Inductive biases, pretraining and fine-tuning jointly account for brain responses to speech](https://arxiv.org/abs/2103.01032)
---------
Millet & King, <i>arXiv</i> 2021

<b>tl;dr:</b>Do convolutional networks process speech sounds like our brains does? Short answer: yes, even without training; but training helps.

<blockquote class="twitter-tweet" data-lang="en" data-theme="light"><p lang="en" dir="ltr">Do convolutional networks process speech sounds like our brains does?<br><br>Check out our latest study with Juliette Millet: <a href="https://t.co/dcupYxSxKA">https://t.co/dcupYxSxKA</a><br><br>Here is the summary thread üëá: 1/n <a href="https://t.co/LI6kr8PY9j">pic.twitter.com/LI6kr8PY9j</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1369230423545548807?ref_src=twsrc%5Etfw">March 9, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


[Deep Recurrent Encoder: A scalable end-to-end network to model brain signals](https://arxiv.org/abs/2103.02339)
---------
Chehab\*, Defossez\*, Loiseau, Gramfort & King, <i>arXiv</i> 2021

<b>tl;dr:</b> We propose a new end-to-end architecture to encode MEG brain signals. It outperforms standard pipelines by a 3X.

<blockquote class="twitter-tweet" data-lang="en" data-theme="light"><p lang="en" dir="ltr">Deep learning improves the analysis of time-resolved brain signals by ... 3Ô∏è‚É£ folds!<br> <br>Check out our latest paper by <a href="https://twitter.com/lomarchehab?ref_src=twsrc%5Etfw">@lomarchehab</a>*, <a href="https://twitter.com/honualx?ref_src=twsrc%5Etfw">@honualx</a>*, <a href="https://twitter.com/loiseau_jc?ref_src=twsrc%5Etfw">@loiseau_jc</a>, and <a href="https://twitter.com/agramfort?ref_src=twsrc%5Etfw">@agramfort</a>:<br> <a href="https://t.co/QxTxoySnBs">https://t.co/QxTxoySnBs</a><br> <br>Below is the summary thread üëá <a href="https://t.co/h1WcoGm7UD">pic.twitter.com/h1WcoGm7UD</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1379775034579947520?ref_src=twsrc%5Etfw">April 7, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

[Bifurcation in brain dynamics reveals a signature of conscious processing independent of report](https://www.nature.com/articles/s41467-021-21393-z)
---------
Sergent, Corazzol, Labouret, Stockart, Wexler,King, Meyniel & Pressnitzer , <i>Nature Communications</i> 2021

<b>tl;dr:</b> We show with EEG that the conscious access follows an all-or-none dynamics even without report.

<blockquote class="twitter-tweet" data-lang="en" data-theme="light"><p lang="en" dir="ltr">Most work on the neural basis of consciousness relies on self-report, however <a href="https://twitter.com/MmeJeanserre?ref_src=twsrc%5Etfw">@MmeJeanserre</a>, <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a> et al. suggest bifurcation in EEG brain dynamics may reflect an independent signature of conscious perception <a href="https://twitter.com/Univ_Paris?ref_src=twsrc%5Etfw">@Univ_Paris</a> <a href="https://twitter.com/Cognition_ENS?ref_src=twsrc%5Etfw">@Cognition_ENS</a> <a href="https://twitter.com/mne_python?ref_src=twsrc%5Etfw">@mne_python</a> <a href="https://t.co/nHMPaSVxnU">https://t.co/nHMPaSVxnU</a> <a href="https://t.co/n4TXgh2XNt">pic.twitter.com/n4TXgh2XNt</a></p>&mdash; Nature Communications (@NatureComms) <a href="https://twitter.com/NatureComms/status/1363133556080316417?ref_src=twsrc%5Etfw">February 20, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

[Language processing in brains and deep neural networks: computational convergence and its limits](https://www.biorxiv.org/content/10.1101/2020.07.03.186288v1.full.pdf)
---------

Caucheteux & King, <i>bioRxiv</i> 2020

<b>tl;dr:</b> Do deep nets become increasingly correlated with brain activity as
they learn to process language? Short answer: only their middle layers do.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Language processing in brains and deep networks: computational convergence and its limits.<br><br>Check out our latest preprint: <a href="https://t.co/HBVkNVtxUl">https://t.co/HBVkNVtxUl</a>, by <a href="https://twitter.com/c_caucheteux?ref_src=twsrc%5Etfw">@c_caucheteux</a> and I <a href="https://t.co/yahwk2fXCY">pic.twitter.com/yahwk2fXCY</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1280173629280595974?ref_src=twsrc%5Etfw">July 6, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


[Back-to-back regression: Disentangling the influence of correlated factors from multivariate observations](https://www.sciencedirect.com/science/article/pii/S1053811920305140)
---------

King, Charton, Lopez-Paz & Oquab, <i>Neuroimage</i> 2020

<b>tl;dr:</b> We introduce a simple method to combine the advantages of decoding
and encoding analyses.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Back-to-back regression: Disentangling the influence of correlated factors from multivariate observations.<br><br>Our latest paper with <a href="https://twitter.com/f_charton?ref_src=twsrc%5Etfw">@f_charton</a>, David Lopez Paz &amp; Maxime Oquab at <a href="https://twitter.com/facebookai?ref_src=twsrc%5Etfw">@facebookai</a> is now freely available at Neuroimage: <a href="https://t.co/2hBgODEeAw">https://t.co/2hBgODEeAw</a><br><br>Here&#39;s the summary thread ‚§µÔ∏è <a href="https://t.co/i1ZLF2dZ5e">pic.twitter.com/i1ZLF2dZ5e</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1281164558141403137?ref_src=twsrc%5Etfw">July 9, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


[COVID-19: the promises and pitfalls of Machine Learning](https://www.nature.com/articles/s42256-020-0181-6)
---------

Peiffer-Smadja, Maatoug, Lescure, D‚ÄôOrtenzio, Pineau & King, <i>Nature Machine Intelligence</i> 2020

<b>tl;dr:</b> We're teaming up with the AP-HP hospital to review the
promises and pitfalls of Machine Learning.

<blockquote class="twitter-tweet" data-theme="light"><br><br>&quot;<a href="https://twitter.com/hashtag/MachineLearning?src=hash&amp;ref_src=twsrc%5Etfw">#MachineLearning</a> for <a href="https://twitter.com/hashtag/COVID%E3%83%BC19?src=hash&amp;ref_src=twsrc%5Etfw">#COVID„Éº19</a> needs global collaboration and data-sharing&quot;<br><br>üëâ<a href="https://t.co/ouY7MYX59p">https://t.co/ouY7MYX59p</a><br><br> <a href="https://twitter.com/hashtag/ArtificialIntelligence?src=hash&amp;ref_src=twsrc%5Etfw">#ArtificialIntelligence</a> <a href="https://twitter.com/hashtag/SARSCoV2?src=hash&amp;ref_src=twsrc%5Etfw">#SARSCoV2</a> <a href="https://t.co/lZsZh8Hqvm">pic.twitter.com/lZsZh8Hqvm</a></p>&mdash; Nathan Peiffer-Smadja (@nathanpsmad) <a href="https://twitter.com/nathanpsmad/status/1263862383308689409?ref_src=twsrc%5Etfw">May 22, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

[Neural dynamics of phoneme sequencing](https://www.biorxiv.org/content/10.1101/2020.04.04.025684v1.full.pdf)
---------
Gwilliams, King, Marantz & Poeppel, <i>bioRxiv</i> 2020

<b>tl;dr:</b> Decoding the neural dynamics underlying phonetic representations shows how
the brain can keep up multiple phonemes until the corresponding word is identified.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">our new paper &quot;Neural dynamics of phoneme sequencing&quot; is now on bioRxiv!<a href="https://t.co/jeTipPTXuf">https://t.co/jeTipPTXuf</a><br><br>conducted with dream-team <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a> <a href="https://twitter.com/AlecMarantz?ref_src=twsrc%5Etfw">@AlecMarantz</a> <a href="https://twitter.com/davidpoeppel?ref_src=twsrc%5Etfw">@davidpoeppel</a>, we use MEG to study how phonemes are processed in continuous naturalistic speech<br><br>short summary in thread below:<br>1/8 <a href="https://t.co/yT5bN2PfHw">pic.twitter.com/yT5bN2PfHw</a></p>&mdash; Laura Gwilliams (@GwilliamsL) <a href="https://twitter.com/GwilliamsL/status/1247216879992782848?ref_src=twsrc%5Etfw">April 6, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

[Intersecting AI and Neuroscience](https://www.ens.psl.eu/actualites/jean-remi-king-entre-ia-et-neurosciences)
---------
<blockquote class="twitter-tweet"><p lang="fr" dir="ltr">Entre <a href="https://twitter.com/hashtag/IA?src=hash&amp;ref_src=twsrc%5Etfw">#IA</a> et neurosciences. Rencontre avec Jean-R√©mi King <a href="https://twitter.com/JeanRemiKing?ref_src=twsrc%5Etfw">@JeanRemiKing</a> <a href="https://twitter.com/Cognition_ENS?ref_src=twsrc%5Etfw">@Cognition_ENS</a>, chercheur <a href="https://twitter.com/CNRS?ref_src=twsrc%5Etfw">@CNRS</a> sp√©cialiste du fonctionnement du cerveau humain üß† <a href="https://t.co/6hxwyGHECP">https://t.co/6hxwyGHECP</a> <a href="https://t.co/cAnJwbbbCj">pic.twitter.com/cAnJwbbbCj</a></p>&mdash; √âcole normale sup√©rieure | PSL (@ENS_ULM) <a href="https://twitter.com/ENS_ULM/status/1237414108091297796?ref_src=twsrc%5Etfw">March 10, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


[The Human Brain Encodes a Chronicle of Visual Events at Each Instant of Time Through the Multiplexing of Traveling Waves](https://www.jneurosci.org/content/41/34/7224.abstract)
---------
Wyart and King, <i>Journal of Neuroscience</i> 2021

<b>tl;dr:</b> We measure brain responses to image sequences, and show how the brain recruits a hierarchy of neural processes in order to efficiently represents multiple snapshots of the past. [Check-out our tweet thread for the illustrated summary](https://twitter.com/JeanRemiKing/status/1196808278929526786?ref_src=twsrc%5Etfw)

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;The Human Brain encodes a Chronicle of Visual Events at each Instant of Time&quot;, by <a href="https://twitter.com/valentinwyart?ref_src=twsrc%5Etfw">@valentinwyart</a> and I: the tl;dr thread: <a href="https://t.co/YfLLZ1ZStr">https://t.co/YfLLZ1ZStr</a> <a href="https://t.co/iySGP52al9">pic.twitter.com/iySGP52al9</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1196808278929526786?ref_src=twsrc%5Etfw">November 19, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


[Recurrent Processes Emulate a Cascade of Hierarchical Decisions](https://www.biorxiv.org/content/biorxiv/early/2019/11/12/840074.full.pdf)
----
Gwilliams and King <i>bioRxiv</i> 2019

<b>tl;dr:</b> When an image is ambiguous, the brain slowly recruits a hierarchy of recurrent processes to generate categorical percepts. [Check-out our tweet thread for the illustrated summary](https://twitter.com/JeanRemiKing/status/1195380648560615425?ref_src=twsrc%5Etfw)

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">0/9: &quot;Recurrent Processes Emulate a Cascade of Hierarchical Decisions&quot;, by <a href="https://twitter.com/GwilliamsL?ref_src=twsrc%5Etfw">@GwilliamsL</a> and I, the tl;dr thread:</p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1195380469031792641?ref_src=twsrc%5Etfw">November 15, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<blockquote class="twitter-tweet" data-conversation="none"><p lang="en" dir="ltr">3/9 Their average brain response confirm a fast feedforward recruitment of their visual hierarchies <a href="https://t.co/Y39WYwJ2Yx">pic.twitter.com/Y39WYwJ2Yx</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1195380648560615425?ref_src=twsrc%5Etfw">November 15, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

[Detection of Brain Activation in Unresponsive Patients with Acute Brain Injury](https://www.nejm.org/doi/pdf/10.1056/NEJMoa1812757?casa_token=JfUB9yyfA1YAAAAA:P4OJxqnKvGq2nUo2Nwgv8n68c4uFYoKh22ySy0pQCE6KGb_qO_qdGpG2hcpuwkxaRv1BgWQqsWlxsLE)
----
Claassen et al, <i>New England Journal of Medicine</i> 2019

<b>tl;dr:</b> Acute brain injury patients can sometimes be behaviorally unresponsive. Yet, we show that 15% of them still demonstrate motor-command brain responses.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">The covering of our latest study in the New York Times: <a href="https://t.co/7qBuerdsKD">https://t.co/7qBuerdsKD</a> <a href="https://t.co/60Cvpv08d5">pic.twitter.com/60Cvpv08d5</a></p>&mdash; Jean-R√©mi King (@JeanRemiKing) <a href="https://twitter.com/JeanRemiKing/status/1144529142760845312?ref_src=twsrc%5Etfw">June 28, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
